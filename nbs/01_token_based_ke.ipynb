{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 6.4MB 29.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 460kB 40.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 624kB 38.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 10.1MB 35.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip install -q spacy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tokens_ke\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Knowledge Extraction\n",
    "> Extract token knowledge from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-19 14:40:18.859194: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Collecting en-core-web-sm==3.1.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6MB 221kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.1.0) (3.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.41.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.23.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Found existing installation: en-core-web-sm 2.2.5\n",
      "    Uninstalling en-core-web-sm-2.2.5:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.5\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TokenKnowledgeExtractor:\n",
    "  \"\"\"Extract knowledge like token, lemma,pos, tags, noun chunks etc.\"\"\"\n",
    "  def __init__(self, spacy_model=\"en_core_web_sm\"):\n",
    "    try:\n",
    "      self.nlp = spacy.load(spacy_model)\n",
    "    except:\n",
    "      print('Please download en_core_web_sm using your cmd- python -m spacy download en_core_web_sm')\n",
    "\n",
    "  def __get_token_knowledge(self, doc):\n",
    "    results = []\n",
    "    for token in doc:\n",
    "        token_info = {}\n",
    "        token_info['token'] = token.text\n",
    "        token_info['lemma'] = token.lemma_\n",
    "        token_info['pos'] = token.pos_\n",
    "        token_info['tag'] = token.tag_\n",
    "        token_info['is_alpha'] = token.is_alpha\n",
    "        token_info['is_stop'] = token.is_stop\n",
    "        results.append(token_info)\n",
    "    return results\n",
    "\n",
    "  def __get_noun_chunks_knowledge(self, doc):\n",
    "    results = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_info = {}\n",
    "        chunk_info['chunk'] = chunk.text\n",
    "        chunk_info['root_text'] = chunk.root.text\n",
    "        chunk_info['root_dep'] = chunk.root.dep_\n",
    "        chunk_info['root_head'] = chunk.root.head.text\n",
    "        results.append(chunk_info)\n",
    "    return results\n",
    "\n",
    "  def extract(self, text):\n",
    "    extracted_info = {\n",
    "        'raw_text':text\n",
    "    }\n",
    "    docs = self.nlp(text)\n",
    "    sents = docs.sents\n",
    "    extracted_info[\"sents\"] = []\n",
    "    for sent in sents:\n",
    "        sent_info = {}\n",
    "        sent_info[\"text\"] = sent.text\n",
    "        sent_info[\"tokens\"] = self.__get_token_knowledge(sent)\n",
    "        sent_info[\"noun_chunks\"] = self.__get_noun_chunks_knowledge(sent)\n",
    "        extracted_info[\"sents\"].append(sent_info)\n",
    "    return extracted_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TokenKnowledgeExtractor` is used to extract token based information or knowledge i.e lemma, pos, tags, noun_chunks etc. We have used spacy package to extract information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ke = TokenKnowledgeExtractor(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Days of riots and looting in South Africa have left more than 70 people dead, hurt thousands of businesses and damaged major infrastructure in some of the worst civil unrest since the end of white minority rule in 1994.\n",
    "The unrest started after former President Jacob Zuma handed himself over last week to start a 15-month prison sentence for contempt of court.\n",
    "JOHANNESBURG, July 14 (Reuters) - Days of riots and looting in South Africa have left more than 70 people dead, hurt thousands of businesses and damaged major infrastructure in some of the worst civil unrest since the end of white minority rule in 1994.\n",
    "\n",
    "What is driving the violence?\n",
    "\n",
    "ZUMA'S JAILING\n",
    "\n",
    "The unrest started after former President Jacob Zuma handed himself over last week to start a 15-month prison sentence for contempt of court.\n",
    "\n",
    "Zuma supporters, who believe he is the victim of a political witch-hunt, burned tyres and blocked roads in his home province of KwaZulu-Natal.\n",
    "\n",
    "Support for Zuma stems partly from his image as a man of the people during his nine years in power until 2018, and because some see his jailing as an attack on the nation's largest ethnic group, the Zulu.\n",
    "\n",
    "Although many wealthy and middle-class South Africans were overjoyed when Zuma was ousted after multiple sleaze and graft allegations, he still retains loyal followings in KwaZulu-Natal and some poor, rural areas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_info = token_ke.extract(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noun_chunks': [{'chunk': 'The unrest',\n",
       "   'root_dep': 'nsubj',\n",
       "   'root_head': 'started',\n",
       "   'root_text': 'unrest'},\n",
       "  {'chunk': 'former President Jacob Zuma',\n",
       "   'root_dep': 'nsubj',\n",
       "   'root_head': 'handed',\n",
       "   'root_text': 'Zuma'},\n",
       "  {'chunk': 'himself',\n",
       "   'root_dep': 'dobj',\n",
       "   'root_head': 'handed',\n",
       "   'root_text': 'himself'},\n",
       "  {'chunk': 'last week',\n",
       "   'root_dep': 'pobj',\n",
       "   'root_head': 'over',\n",
       "   'root_text': 'week'},\n",
       "  {'chunk': 'a 15-month prison sentence',\n",
       "   'root_dep': 'dobj',\n",
       "   'root_head': 'start',\n",
       "   'root_text': 'sentence'},\n",
       "  {'chunk': 'contempt',\n",
       "   'root_dep': 'pobj',\n",
       "   'root_head': 'for',\n",
       "   'root_text': 'contempt'},\n",
       "  {'chunk': 'court',\n",
       "   'root_dep': 'pobj',\n",
       "   'root_head': 'of',\n",
       "   'root_text': 'court'}],\n",
       " 'text': 'The unrest started after former President Jacob Zuma handed himself over last week to start a 15-month prison sentence for contempt of court.',\n",
       " 'tokens': [{'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'the',\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'token': 'The'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'unrest',\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'token': 'unrest'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'start',\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'VBD',\n",
       "   'token': 'started'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'after',\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'token': 'after'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'former',\n",
       "   'pos': 'ADJ',\n",
       "   'tag': 'JJ',\n",
       "   'token': 'former'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'President',\n",
       "   'pos': 'PROPN',\n",
       "   'tag': 'NNP',\n",
       "   'token': 'President'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'Jacob',\n",
       "   'pos': 'PROPN',\n",
       "   'tag': 'NNP',\n",
       "   'token': 'Jacob'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'Zuma',\n",
       "   'pos': 'PROPN',\n",
       "   'tag': 'NNP',\n",
       "   'token': 'Zuma'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'hand',\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'VBD',\n",
       "   'token': 'handed'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'himself',\n",
       "   'pos': 'PRON',\n",
       "   'tag': 'PRP',\n",
       "   'token': 'himself'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'over',\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'token': 'over'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'last',\n",
       "   'pos': 'ADJ',\n",
       "   'tag': 'JJ',\n",
       "   'token': 'last'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'week',\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'token': 'week'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'to',\n",
       "   'pos': 'PART',\n",
       "   'tag': 'TO',\n",
       "   'token': 'to'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'start',\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'VB',\n",
       "   'token': 'start'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'a',\n",
       "   'pos': 'DET',\n",
       "   'tag': 'DT',\n",
       "   'token': 'a'},\n",
       "  {'is_alpha': False,\n",
       "   'is_stop': False,\n",
       "   'lemma': '15',\n",
       "   'pos': 'NUM',\n",
       "   'tag': 'CD',\n",
       "   'token': '15'},\n",
       "  {'is_alpha': False,\n",
       "   'is_stop': False,\n",
       "   'lemma': '-',\n",
       "   'pos': 'PUNCT',\n",
       "   'tag': 'HYPH',\n",
       "   'token': '-'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'month',\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'token': 'month'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'prison',\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'token': 'prison'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'sentence',\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'token': 'sentence'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'for',\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'token': 'for'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'contempt',\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'token': 'contempt'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': True,\n",
       "   'lemma': 'of',\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'token': 'of'},\n",
       "  {'is_alpha': True,\n",
       "   'is_stop': False,\n",
       "   'lemma': 'court',\n",
       "   'pos': 'NOUN',\n",
       "   'tag': 'NN',\n",
       "   'token': 'court'},\n",
       "  {'is_alpha': False,\n",
       "   'is_stop': False,\n",
       "   'lemma': '.',\n",
       "   'pos': 'PUNCT',\n",
       "   'tag': '.',\n",
       "   'token': '.'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_info['sents'][2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
