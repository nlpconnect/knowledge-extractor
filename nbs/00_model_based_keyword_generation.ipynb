{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip install -q transformers nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp keyword_generators\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Generation\n",
    "> Generate keywords from given input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from transformers import TextGenerationPipeline, TFAutoModelForPreTraining, TFBartForConditionalGeneration, BartTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BartKeywordGenerator():\n",
    "  \"\"\"\n",
    "  Bart based keyword generator using huggingface transformers\n",
    "  \"\"\"\n",
    "  def __init__(self, model_name, use_cuda=False):\n",
    "    self.model_name = model_name\n",
    "    self.model = TFBartForConditionalGeneration.from_pretrained(self.model_name, from_pt=True)\n",
    "    self.tokenizer = BartTokenizer.from_pretrained(self.model_name)\n",
    "    self.use_cuda = use_cuda\n",
    "    self.device = 0 if use_cuda else -1\n",
    "    self.keyword_generator = pipeline(\"summarization\", model=self.model, tokenizer=self.tokenizer, device=self.device)\n",
    "\n",
    "  def generate(self, text, max_length=50, **kwargs):\n",
    "\n",
    "    generated_keywords = self.keyword_generator(text, max_length=max_length, **kwargs)\n",
    "    keywords = []\n",
    "    for keyword in generated_keywords:\n",
    "      keywords.append({\"keywords\": keyword['summary_text'].split(\";\")})\n",
    "    return keywords\n",
    "\n",
    "  def batch_generate(self, texts, batch_size=8, max_length=50, **kwargs):\n",
    "    \n",
    "    batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]\n",
    "    keywords = []\n",
    "\n",
    "    for batch in batches:\n",
    "      batch_keywords = self.generate(batch, max_length=max_length, **kwargs)\n",
    "      keywords.extend(batch_keywords)\n",
    "    return keywords    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BartKeywordGenerator` is a base class for keyword generator. It is implemented based on huggingface transformer lib.\n",
    "\n",
    "It has two function:\n",
    "\n",
    "\n",
    "\n",
    "1.   `generate()`: Given text input it will generate keywords. The parameters are based on transformers .generate arguments. \n",
    "2.   `batch_generate()`: Given a list of text inputs. Firstly it will split into batches and then generate.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExtractiveKeywordGenerator(BartKeywordGenerator):\n",
    "  \"\"\"It will generate extractive keywords using bart based fined tunned model on openkp datasets\"\"\"\n",
    "  def __init__(self, use_cuda=False):\n",
    "    model_name = \"ankur310794/bart-base-keyphrase-generation-openkp\"\n",
    "    super().__init__(model_name, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ExtractiveKeywordGenerator` implements `BartKeywordGenerator` for extractive keyword generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AbstractiveKeywordGenerator(BartKeywordGenerator):\n",
    "  \"\"\"It will generate abstractive keywords using bart based fined tunned model on kpTimes dataset\"\"\"\n",
    "  def __init__(self, use_cuda=False):\n",
    "    model_name = \"ankur310794/bart-base-keyphrase-generation-kpTimes\"\n",
    "    super().__init__(model_name, use_cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AbstractiveKeywordGenerator` implements `BartKeywordGenerator` for abstractive keyword generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForConditionalGeneration: ['lm_head.weight']\n",
      "- This IS expected if you are initializing TFBartForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "extractive_generator = ExtractiveKeywordGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForConditionalGeneration: ['lm_head.weight']\n",
      "- This IS expected if you are initializing TFBartForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "abstractive_generator = AbstractiveKeywordGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'keywords': ['The death toll in Germany', ' Belgium', ' historic flood']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractive_generator.generate(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'keywords': ['The death toll in Germany', ' Belgium', ' historic flood']},\n",
       " {'keywords': ['The death toll in Germany', ' Belgium', ' historic flood']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractive_generator.batch_generate([input_text, input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'keywords': ['Floods', 'Germany', 'Belgium', 'Europe']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstractive_generator.generate(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'keywords': ['The death toll in Germany', ' Belgium', ' historic flood']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractive_generator.generate(input_text, min_length=10, num_beams=5, \n",
    "    early_stopping=True, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'keywords': ['The death toll in Germany', ' Belgium', ' historic flood']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractive_generator.generate(input_text, do_sample=True, max_length=50, top_k=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
